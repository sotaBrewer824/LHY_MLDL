{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5266736,"sourceType":"datasetVersion","datasetId":3065496}],"dockerImageVersionId":30445,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# HW6 Diffusion Model\n\n**Sources:**\n- Github implementation [Denoising Diffusion Pytorch](https://github.com/lucidrains/denoising-diffusion-pytorch)\n- Papers on Diffusion models ([Dhariwal, Nichol, 2021], [Ho et al., 2020] ect.)\n","metadata":{"id":"HhIgGq3za0yh"}},{"cell_type":"markdown","source":"## Import Packages and Set Seeds","metadata":{"id":"wLHSIArLcFK0"}},{"cell_type":"code","source":"!pip install einops\n!pip install transformers\n!pip install ema_pytorch\n!pip install accelerate","metadata":{"id":"s1xegyILIuLz","outputId":"b71ce929-c0bd-4ff0-ff53-cb01b421c2e9","execution":{"iopub.status.busy":"2024-06-28T11:51:38.492209Z","iopub.execute_input":"2024-06-28T11:51:38.493206Z","iopub.status.idle":"2024-06-28T11:52:27.003753Z","shell.execute_reply.started":"2024-06-28T11:51:38.493166Z","shell.execute_reply":"2024-06-28T11:52:27.002492Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting einops\n  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: einops\nSuccessfully installed einops-0.6.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.27.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting ema_pytorch\n  Downloading ema_pytorch-0.5.1-py3-none-any.whl (8.7 kB)\nRequirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.7/site-packages (from ema_pytorch) (1.13.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.6->ema_pytorch) (4.4.0)\nInstalling collected packages: ema_pytorch\nSuccessfully installed ema_pytorch-0.5.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: accelerate in /opt/conda/lib/python3.7/site-packages (0.12.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from accelerate) (23.0)\nRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from accelerate) (1.13.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from accelerate) (6.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from accelerate) (1.21.6)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4.0->accelerate) (4.4.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import math\nimport copy\nfrom pathlib import Path\nfrom random import random\nfrom functools import partial\nfrom collections import namedtuple\nfrom multiprocessing import cpu_count\n\nimport torch\nfrom torch import nn, einsum\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom torch.optim import Adam\n\nimport torchvision\nfrom torchvision import transforms as T, utils\n\nfrom einops import rearrange, reduce, repeat\nfrom einops.layers.torch import Rearrange\n\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nfrom ema_pytorch import EMA\n\nfrom accelerate import Accelerator\nimport matplotlib.pyplot as plt\nimport os\n\ntorch.backends.cudnn.benchmark = True\ntorch.manual_seed(4096)\n\nif torch.cuda.is_available():\n  torch.cuda.manual_seed(4096)","metadata":{"id":"LQnlc27k7Aiw","outputId":"122e675a-a91b-4fa3-d56f-1f6bb38bc094","execution":{"iopub.status.busy":"2024-06-28T11:52:27.006996Z","iopub.execute_input":"2024-06-28T11:52:27.008070Z","iopub.status.idle":"2024-06-28T11:52:31.265140Z","shell.execute_reply.started":"2024-06-28T11:52:27.008013Z","shell.execute_reply":"2024-06-28T11:52:31.263957Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Step 1: Forward process (Noise scheduler)\n\n\n","metadata":{"id":"Rj17psVw7Shg"}},{"cell_type":"code","source":"def linear_beta_schedule(timesteps):\n    \"\"\"\n    linear schedule, proposed in original ddpm paper\n    \"\"\"\n    scale = 1000 / timesteps\n    beta_start = scale * 0.0001\n    beta_end = scale * 0.02\n    return torch.linspace(beta_start, beta_end, timesteps, dtype = torch.float64)\n\ndef extract(a, t, x_shape):\n    b, *_ = t.shape\n    out = a.gather(-1, t)\n    return out.reshape(b, *((1,) * (len(x_shape) - 1)))","metadata":{"id":"qWw50ui9IZ5q","execution":{"iopub.status.busy":"2024-06-28T11:52:31.266618Z","iopub.execute_input":"2024-06-28T11:52:31.266919Z","iopub.status.idle":"2024-06-28T11:52:31.274748Z","shell.execute_reply.started":"2024-06-28T11:52:31.266878Z","shell.execute_reply":"2024-06-28T11:52:31.273646Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def cosine_beta_schedule(timesteps, s = 0.008):\n    \"\"\"\n    cosine schedule\n    as proposed in https://openreview.net/forum?id=-NEXDKk8gZ\n    \"\"\"\n    steps = timesteps + 1\n    t = torch.linspace(0, timesteps, steps, dtype = torch.float64) / timesteps\n    alphas_cumprod = torch.cos((t + s) / (1 + s) * math.pi * 0.5) ** 2\n    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n    return torch.clip(betas, 0, 0.999)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T11:52:31.277176Z","iopub.execute_input":"2024-06-28T11:52:31.277474Z","iopub.status.idle":"2024-06-28T11:52:31.288698Z","shell.execute_reply.started":"2024-06-28T11:52:31.277445Z","shell.execute_reply":"2024-06-28T11:52:31.287837Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Create dataset","metadata":{"id":"Vt6JSKawk7_b"}},{"cell_type":"code","source":"class Dataset(Dataset):\n    def __init__(\n        self,\n        folder,\n        image_size\n    ):\n        self.folder = folder\n        self.image_size = image_size\n        self.paths = [p for p in Path(f'{folder}').glob(f'**/*.jpg')]\n        #################################\n        ## TODO: Data Augmentation ##\n        #################################\n        self.transform = T.Compose([\n            T.Resize(image_size),\n            T.RandomHorizontalFlip(0.5),\n            T.RandomVerticalFlip(0.5),\n            T.RandomRotation(180),\n            T.ToTensor()\n        ])\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, index):\n        path = self.paths[index]\n        img = Image.open(path)\n        return self.transform(img)","metadata":{"id":"uuckjpW_k1LN","execution":{"iopub.status.busy":"2024-06-28T11:52:31.289861Z","iopub.execute_input":"2024-06-28T11:52:31.290165Z","iopub.status.idle":"2024-06-28T11:52:31.300572Z","shell.execute_reply.started":"2024-06-28T11:52:31.290138Z","shell.execute_reply":"2024-06-28T11:52:31.299580Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Step 2: The backward process = U-Net\n\n","metadata":{"id":"buW6BaNga-XH"}},{"cell_type":"markdown","source":"Define some useful functions and U-Net","metadata":{"id":"iYw6u0nJXIWy"}},{"cell_type":"markdown","source":"### Attention Module","metadata":{}},{"cell_type":"code","source":"from functools import wraps\nfrom packaging import version\nfrom collections import namedtuple\n\nimport torch\nfrom torch import nn, einsum\nimport torch.nn.functional as F\n\nfrom einops import rearrange\n\n# constants\n\nAttentionConfig = namedtuple('AttentionConfig', ['enable_flash', 'enable_math', 'enable_mem_efficient'])\n\n# helpers\n\ndef exists(val):\n    return val is not None\n\ndef default(val, d):\n    return val if exists(val) else d\n\ndef once(fn):\n    called = False\n    @wraps(fn)\n    def inner(x):\n        nonlocal called\n        if called:\n            return\n        called = True\n        return fn(x)\n    return inner\n\nprint_once = once(print)\n\n# main class\n\nclass Attend(nn.Module):\n    def __init__(\n        self,\n        dropout = 0.,\n        flash = False,\n        scale = None\n    ):\n        super().__init__()\n        self.dropout = dropout\n        self.scale = scale\n        self.attn_dropout = nn.Dropout(dropout)\n\n        self.flash = flash\n        assert not (flash and version.parse(torch.__version__) < version.parse('2.0.0')), 'in order to use flash attention, you must be using pytorch 2.0 or above'\n\n        # determine efficient attention configs for cuda and cpu\n\n        self.cpu_config = AttentionConfig(True, True, True)\n        self.cuda_config = None\n\n        if not torch.cuda.is_available() or not flash:\n            return\n\n        device_properties = torch.cuda.get_device_properties(torch.device('cuda'))\n\n        device_version = version.parse(f'{device_properties.major}.{device_properties.minor}')\n\n        if device_version > version.parse('8.0'):\n            print_once('A100 GPU detected, using flash attention if input tensor is on cuda')\n            self.cuda_config = AttentionConfig(True, False, False)\n        else:\n            print_once('Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda')\n            self.cuda_config = AttentionConfig(False, True, True)\n\n    def flash_attn(self, q, k, v):\n        _, heads, q_len, _, k_len, is_cuda, device = *q.shape, k.shape[-2], q.is_cuda, q.device\n\n        if exists(self.scale):\n            default_scale = q.shape[-1]\n            q = q * (self.scale / default_scale)\n\n        q, k, v = map(lambda t: t.contiguous(), (q, k, v))\n\n        # Check if there is a compatible device for flash attention\n\n        config = self.cuda_config if is_cuda else self.cpu_config\n\n        # pytorch 2.0 flash attn: q, k, v, mask, dropout, causal, softmax_scale\n\n        with torch.backends.cuda.sdp_kernel(**config._asdict()):\n            out = F.scaled_dot_product_attention(\n                q, k, v,\n                dropout_p = self.dropout if self.training else 0.\n            )\n\n        return out\n\n    def forward(self, q, k, v):\n        \"\"\"\n        einstein notation\n        b - batch\n        h - heads\n        n, i, j - sequence length (base sequence length, source, target)\n        d - feature dimension\n        \"\"\"\n\n        q_len, k_len, device = q.shape[-2], k.shape[-2], q.device\n\n        if self.flash:\n            return self.flash_attn(q, k, v)\n\n        scale = default(self.scale, q.shape[-1] ** -0.5)\n\n        # similarity\n\n        sim = einsum(f\"b h i d, b h j d -> b h i j\", q, k) * scale\n\n        # attention\n\n        attn = sim.softmax(dim = -1)\n        attn = self.attn_dropout(attn)\n\n        # aggregate values\n\n        out = einsum(f\"b h i j, b h j d -> b h i d\", attn, v)\n\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-06-28T11:52:31.302056Z","iopub.execute_input":"2024-06-28T11:52:31.302598Z","iopub.status.idle":"2024-06-28T11:52:31.327657Z","shell.execute_reply.started":"2024-06-28T11:52:31.302560Z","shell.execute_reply":"2024-06-28T11:52:31.326682Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# helpers functions\n\ndef exists(x):\n    return x is not None\n\ndef default(val, d):\n    if exists(val):\n        return val\n    return d() if callable(d) else d\n\ndef cast_tuple(t, length = 1):\n    if isinstance(t, tuple):\n        return t\n    return ((t,) * length)\n\ndef divisible_by(numer, denom):\n    return (numer % denom) == 0\n\ndef identity(t, *args, **kwargs):\n    return t\n\ndef cycle(dl):\n    while True:\n        for data in dl:\n            yield data\n\ndef has_int_squareroot(num):\n    return (math.sqrt(num) ** 2) == num\n\ndef num_to_groups(num, divisor):\n    groups = num // divisor\n    remainder = num % divisor\n    arr = [divisor] * groups\n    if remainder > 0:\n        arr.append(remainder)\n    return arr\n\ndef convert_image_to_fn(img_type, image):\n    if image.mode != img_type:\n        return image.convert(img_type)\n    return image\n\n# normalization functions\n\ndef normalize_to_neg_one_to_one(img):\n    return img * 2 - 1\n\ndef unnormalize_to_zero_to_one(t):\n    return (t + 1) * 0.5\n\n# small helper modules\n\ndef Upsample(dim, dim_out = None):\n    return nn.Sequential(\n        nn.Upsample(scale_factor = 2, mode = 'nearest'),\n        nn.Conv2d(dim, default(dim_out, dim), 3, padding = 1)\n    )\n\ndef Downsample(dim, dim_out = None):\n    return nn.Sequential(\n        Rearrange('b c (h p1) (w p2) -> b (c p1 p2) h w', p1 = 2, p2 = 2),\n        nn.Conv2d(dim * 4, default(dim_out, dim), 1)\n    )\n\nclass RMSNorm(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.scale = dim ** 0.5\n        self.g = nn.Parameter(torch.ones(1, dim, 1, 1))\n\n    def forward(self, x):\n        return F.normalize(x, dim = 1) * self.g * self.scale\n\n# sinusoidal positional embeds\n\nclass SinusoidalPosEmb(nn.Module):\n    def __init__(self, dim, theta = 10000):\n        super().__init__()\n        self.dim = dim\n        self.theta = theta\n\n    def forward(self, x):\n        device = x.device\n        half_dim = self.dim // 2\n        emb = math.log(self.theta) / (half_dim - 1)\n        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n        emb = x[:, None] * emb[None, :]\n        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n        return emb\n\nclass RandomOrLearnedSinusoidalPosEmb(nn.Module):\n    \"\"\" following @crowsonkb 's lead with random (learned optional) sinusoidal pos emb \"\"\"\n    \"\"\" https://github.com/crowsonkb/v-diffusion-jax/blob/master/diffusion/models/danbooru_128.py#L8 \"\"\"\n\n    def __init__(self, dim, is_random = False):\n        super().__init__()\n        assert divisible_by(dim, 2)\n        half_dim = dim // 2\n        self.weights = nn.Parameter(torch.randn(half_dim), requires_grad = not is_random)\n\n    def forward(self, x):\n        x = rearrange(x, 'b -> b 1')\n        freqs = x * rearrange(self.weights, 'd -> 1 d') * 2 * math.pi\n        fouriered = torch.cat((freqs.sin(), freqs.cos()), dim = -1)\n        fouriered = torch.cat((x, fouriered), dim = -1)\n        return fouriered\n\n# building block modules\n\nclass Block(nn.Module):\n    def __init__(self, dim, dim_out, dropout = 0.):\n        super().__init__()\n        self.proj = nn.Conv2d(dim, dim_out, 3, padding = 1)\n        self.norm = RMSNorm(dim_out)\n        self.act = nn.SiLU()\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, scale_shift = None):\n        x = self.proj(x)\n        x = self.norm(x)\n\n        if exists(scale_shift):\n            scale, shift = scale_shift\n            x = x * (scale + 1) + shift\n\n        x = self.act(x)\n        return self.dropout(x)\n\nclass ResnetBlock(nn.Module):\n    def __init__(self, dim, dim_out, *, time_emb_dim = None, dropout = 0.):\n        super().__init__()\n        self.mlp = nn.Sequential(\n            nn.SiLU(),\n            nn.Linear(time_emb_dim, dim_out * 2)\n        ) if exists(time_emb_dim) else None\n\n        self.block1 = Block(dim, dim_out, dropout = dropout)\n        self.block2 = Block(dim_out, dim_out)\n        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n\n    def forward(self, x, time_emb = None):\n\n        scale_shift = None\n        if exists(self.mlp) and exists(time_emb):\n            time_emb = self.mlp(time_emb)\n            time_emb = rearrange(time_emb, 'b c -> b c 1 1')\n            scale_shift = time_emb.chunk(2, dim = 1)\n\n        h = self.block1(x, scale_shift = scale_shift)\n\n        h = self.block2(h)\n\n        return h + self.res_conv(x)\n\nclass LinearAttention(nn.Module):\n    def __init__(\n        self,\n        dim,\n        heads = 4,\n        dim_head = 32,\n        num_mem_kv = 4\n    ):\n        super().__init__()\n        self.scale = dim_head ** -0.5\n        self.heads = heads\n        hidden_dim = dim_head * heads\n\n        self.norm = RMSNorm(dim)\n\n        self.mem_kv = nn.Parameter(torch.randn(2, heads, dim_head, num_mem_kv))\n        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)\n\n        self.to_out = nn.Sequential(\n            nn.Conv2d(hidden_dim, dim, 1),\n            RMSNorm(dim)\n        )\n\n    def forward(self, x):\n        b, c, h, w = x.shape\n\n        x = self.norm(x)\n\n        qkv = self.to_qkv(x).chunk(3, dim = 1)\n        q, k, v = map(lambda t: rearrange(t, 'b (h c) x y -> b h c (x y)', h = self.heads), qkv)\n\n        mk, mv = map(lambda t: repeat(t, 'h c n -> b h c n', b = b), self.mem_kv)\n        k, v = map(partial(torch.cat, dim = -1), ((mk, k), (mv, v)))\n\n        q = q.softmax(dim = -2)\n        k = k.softmax(dim = -1)\n\n        q = q * self.scale\n\n        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)\n\n        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)\n        out = rearrange(out, 'b h c (x y) -> b (h c) x y', h = self.heads, x = h, y = w)\n        return self.to_out(out)\n\nclass Attention(nn.Module):\n    def __init__(\n        self,\n        dim,\n        heads = 4,\n        dim_head = 32,\n        num_mem_kv = 4,\n        flash = False\n    ):\n        super().__init__()\n        self.heads = heads\n        hidden_dim = dim_head * heads\n\n        self.norm = RMSNorm(dim)\n        self.attend = Attend(flash = flash)\n\n        self.mem_kv = nn.Parameter(torch.randn(2, heads, num_mem_kv, dim_head))\n        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)\n        self.to_out = nn.Conv2d(hidden_dim, dim, 1)\n\n    def forward(self, x):\n        b, c, h, w = x.shape\n\n        x = self.norm(x)\n\n        qkv = self.to_qkv(x).chunk(3, dim = 1)\n        q, k, v = map(lambda t: rearrange(t, 'b (h c) x y -> b h (x y) c', h = self.heads), qkv)\n\n        mk, mv = map(lambda t: repeat(t, 'h n d -> b h n d', b = b), self.mem_kv)\n        k, v = map(partial(torch.cat, dim = -2), ((mk, k), (mv, v)))\n\n        out = self.attend(q, k, v)\n\n        out = rearrange(out, 'b h (x y) d -> b (h d) x y', x = h, y = w)\n        return self.to_out(out)\n\n# model\n\nclass Unet(nn.Module):\n    def __init__(\n        self,\n        dim,\n        init_dim = None,\n        out_dim = None,\n        dim_mults = (1, 2, 4, 8),\n        channels = 3,\n        self_condition = False,\n        learned_variance = False,\n        learned_sinusoidal_cond = False,\n        random_fourier_features = False,\n        learned_sinusoidal_dim = 16,\n        sinusoidal_pos_emb_theta = 10000,\n        dropout = 0.,\n        attn_dim_head = 32,\n        attn_heads = 4,\n        full_attn = None,    # defaults to full attention only for inner most layer\n        flash_attn = False\n    ):\n        super().__init__()\n\n        # determine dimensions\n\n        self.channels = channels\n        self.self_condition = self_condition\n        input_channels = channels * (2 if self_condition else 1)\n\n        init_dim = default(init_dim, dim)\n        self.init_conv = nn.Conv2d(input_channels, init_dim, 7, padding = 3)\n\n        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n        in_out = list(zip(dims[:-1], dims[1:]))\n\n        # time embeddings\n\n        time_dim = dim * 4\n\n        self.random_or_learned_sinusoidal_cond = learned_sinusoidal_cond or random_fourier_features\n\n        if self.random_or_learned_sinusoidal_cond:\n            sinu_pos_emb = RandomOrLearnedSinusoidalPosEmb(learned_sinusoidal_dim, random_fourier_features)\n            fourier_dim = learned_sinusoidal_dim + 1\n        else:\n            sinu_pos_emb = SinusoidalPosEmb(dim, theta = sinusoidal_pos_emb_theta)\n            fourier_dim = dim\n\n        self.time_mlp = nn.Sequential(\n            sinu_pos_emb,\n            nn.Linear(fourier_dim, time_dim),\n            nn.GELU(),\n            nn.Linear(time_dim, time_dim)\n        )\n\n        # attention\n\n        if not full_attn:\n            full_attn = (*((False,) * (len(dim_mults) - 1)), True)\n\n        num_stages = len(dim_mults)\n        full_attn  = cast_tuple(full_attn, num_stages)\n        attn_heads = cast_tuple(attn_heads, num_stages)\n        attn_dim_head = cast_tuple(attn_dim_head, num_stages)\n\n        assert len(full_attn) == len(dim_mults)\n\n        # prepare blocks\n\n        FullAttention = partial(Attention, flash = flash_attn)\n        resnet_block = partial(ResnetBlock, time_emb_dim = time_dim, dropout = dropout)\n\n        # layers\n\n        self.downs = nn.ModuleList([])\n        self.ups = nn.ModuleList([])\n        num_resolutions = len(in_out)\n\n        for ind, ((dim_in, dim_out), layer_full_attn, layer_attn_heads, layer_attn_dim_head) in enumerate(zip(in_out, full_attn, attn_heads, attn_dim_head)):\n            is_last = ind >= (num_resolutions - 1)\n\n            attn_klass = FullAttention if layer_full_attn else LinearAttention\n\n            self.downs.append(nn.ModuleList([\n                resnet_block(dim_in, dim_in),\n                resnet_block(dim_in, dim_in),\n                attn_klass(dim_in, dim_head = layer_attn_dim_head, heads = layer_attn_heads),\n                Downsample(dim_in, dim_out) if not is_last else nn.Conv2d(dim_in, dim_out, 3, padding = 1)\n            ]))\n\n        mid_dim = dims[-1]\n        self.mid_block1 = resnet_block(mid_dim, mid_dim)\n        self.mid_attn = FullAttention(mid_dim, heads = attn_heads[-1], dim_head = attn_dim_head[-1])\n        self.mid_block2 = resnet_block(mid_dim, mid_dim)\n\n        for ind, ((dim_in, dim_out), layer_full_attn, layer_attn_heads, layer_attn_dim_head) in enumerate(zip(*map(reversed, (in_out, full_attn, attn_heads, attn_dim_head)))):\n            is_last = ind == (len(in_out) - 1)\n\n            attn_klass = FullAttention if layer_full_attn else LinearAttention\n\n            self.ups.append(nn.ModuleList([\n                resnet_block(dim_out + dim_in, dim_out),\n                resnet_block(dim_out + dim_in, dim_out),\n                attn_klass(dim_out, dim_head = layer_attn_dim_head, heads = layer_attn_heads),\n                Upsample(dim_out, dim_in) if not is_last else  nn.Conv2d(dim_out, dim_in, 3, padding = 1)\n            ]))\n\n        default_out_dim = channels * (1 if not learned_variance else 2)\n        self.out_dim = default(out_dim, default_out_dim)\n\n        self.final_res_block = resnet_block(init_dim * 2, init_dim)\n        self.final_conv = nn.Conv2d(init_dim, self.out_dim, 1)\n\n    @property\n    def downsample_factor(self):\n        return 2 ** (len(self.downs) - 1)\n\n    def forward(self, x, time, x_self_cond = None):\n        assert all([divisible_by(d, self.downsample_factor) for d in x.shape[-2:]]), f'your input dimensions {x.shape[-2:]} need to be divisible by {self.downsample_factor}, given the unet'\n\n        if self.self_condition:\n            x_self_cond = default(x_self_cond, lambda: torch.zeros_like(x))\n            x = torch.cat((x_self_cond, x), dim = 1)\n\n        x = self.init_conv(x)\n        r = x.clone()\n\n        t = self.time_mlp(time)\n\n        h = []\n\n        for block1, block2, attn, downsample in self.downs:\n            x = block1(x, t)\n            h.append(x)\n\n            x = block2(x, t)\n            x = attn(x) + x\n            h.append(x)\n\n            x = downsample(x)\n\n        x = self.mid_block1(x, t)\n        x = self.mid_attn(x) + x\n        x = self.mid_block2(x, t)\n\n        for block1, block2, attn, upsample in self.ups:\n            x = torch.cat((x, h.pop()), dim = 1)\n            x = block1(x, t)\n\n            x = torch.cat((x, h.pop()), dim = 1)\n            x = block2(x, t)\n            x = attn(x) + x\n\n            x = upsample(x)\n\n        x = torch.cat((x, r), dim = 1)\n\n        x = self.final_res_block(x, t)\n        return self.final_conv(x)\n\n# model = Unet(64)","metadata":{"id":"DuJCCZ5dInQq","execution":{"iopub.status.busy":"2024-06-28T11:52:31.329162Z","iopub.execute_input":"2024-06-28T11:52:31.329471Z","iopub.status.idle":"2024-06-28T11:52:31.410591Z","shell.execute_reply.started":"2024-06-28T11:52:31.329442Z","shell.execute_reply":"2024-06-28T11:52:31.409464Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Step 3: The Diffusion Process\n\n","metadata":{"id":"8B9GlZrotBXy"}},{"cell_type":"markdown","source":"Define diffusion process, including generating noisy models, sample...\n","metadata":{"id":"ph05t8MxXMoY"}},{"cell_type":"code","source":"class GaussianDiffusion(nn.Module):\n    def __init__(\n        self,\n        model,\n        *,\n        image_size,\n        timesteps = 1000,\n        beta_schedule = 'cos',\n        auto_normalize = True\n    ):\n        super().__init__()\n        assert not (type(self) == GaussianDiffusion and model.channels != model.out_dim)\n        assert not model.random_or_learned_sinusoidal_cond\n\n        self.model = model\n\n        self.channels = self.model.channels\n\n        self.image_size = image_size\n\n\n        if beta_schedule == 'linear':\n            beta_schedule_fn = linear_beta_schedule\n        elif beta_schedule == 'cos':\n            beta_schedule_fn = cosine_beta_schedule\n        else:\n            raise ValueError(f'unknown beta schedule {beta_schedule}')\n        \n        # calculate beta and other precalculated parameters\n        betas = beta_schedule_fn(timesteps)\n                                            \n        alphas = 1. - betas\n        alphas_cumprod = torch.cumprod(alphas, dim=0)\n        alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value = 1.)\n\n        timesteps, = betas.shape\n        self.num_timesteps = int(timesteps)\n\n        # sampling related parameters\n\n        self.sampling_timesteps = timesteps # default num sampling timesteps to number of timesteps at training\n\n        # helper function to register buffer from float64 to float32\n\n        register_buffer = lambda name, val: self.register_buffer(name, val.to(torch.float32))\n\n        register_buffer('betas', betas)\n        register_buffer('alphas_cumprod', alphas_cumprod)\n        register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)\n\n        # calculations for diffusion q(x_t | x_{t-1}) and others\n\n        register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))\n        register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))\n        register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))\n        register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))\n        register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))\n\n        # calculations for posterior q(x_{t-1} | x_t, x_0)\n\n        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n\n        # above: equal to 1. / (1. / (1. - alpha_cumprod_tm1) + alpha_t / beta_t)\n\n        register_buffer('posterior_variance', posterior_variance)\n\n        # below: log calculation clipped because the posterior variance is 0 at the beginning of the diffusion chain\n\n        register_buffer('posterior_log_variance_clipped', torch.log(posterior_variance.clamp(min =1e-20)))\n        register_buffer('posterior_mean_coef1', betas * torch.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))\n        register_buffer('posterior_mean_coef2', (1. - alphas_cumprod_prev) * torch.sqrt(alphas) / (1. - alphas_cumprod))\n\n        # derive loss weight\n        # snr - signal noise ratio\n\n        snr = alphas_cumprod / (1 - alphas_cumprod)\n\n        # https://arxiv.org/abs/2303.09556\n\n        maybe_clipped_snr = snr.clone()\n\n        register_buffer('loss_weight', maybe_clipped_snr / snr)\n\n        # auto-normalization of data [0, 1] -> [-1, 1] - can turn off by setting it to be False\n\n        self.normalize = normalize_to_neg_one_to_one if auto_normalize else identity\n        self.unnormalize = unnormalize_to_zero_to_one if auto_normalize else identity\n\n    def predict_start_from_noise(self, x_t, t, noise):\n        return (\n            extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -\n            extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n        )\n\n    def predict_noise_from_start(self, x_t, t, x0):\n        return (\n            (extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t - x0) / \\\n            extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape)\n        )\n\n\n    def q_posterior(self, x_start, x_t, t):\n        posterior_mean = (\n            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +\n            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t\n        )\n        posterior_variance = extract(self.posterior_variance, t, x_t.shape)\n        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)\n        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n\n    def model_predictions(self, x, t, clip_x_start = False, rederive_pred_noise = False):\n        model_output = self.model(x, t)\n        maybe_clip = partial(torch.clamp, min = -1., max = 1.) if clip_x_start else identity\n\n        pred_noise = model_output\n        x_start = self.predict_start_from_noise(x, t, pred_noise)\n        x_start = maybe_clip(x_start)\n\n        if clip_x_start and rederive_pred_noise:\n            pred_noise = self.predict_noise_from_start(x, t, x_start)\n\n        return pred_noise, x_start\n\n    def p_mean_variance(self, x, t, clip_denoised = True):\n        noise, x_start = self.model_predictions(x, t)\n\n        if clip_denoised:\n            x_start.clamp_(-1., 1.)\n\n        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start = x_start, x_t = x, t = t)\n        return model_mean, posterior_variance, posterior_log_variance, x_start\n\n    @torch.no_grad()\n    def p_sample(self, x, t: int):\n        b, *_, device = *x.shape, x.device\n        batched_times = torch.full((b,), t, device = x.device, dtype = torch.long)\n        model_mean, _, model_log_variance, x_start = self.p_mean_variance(x = x, t = batched_times, clip_denoised = True)\n        noise = torch.randn_like(x) if t > 0 else 0. # no noise if t == 0\n        pred_img = model_mean + (0.5 * model_log_variance).exp() * noise\n        return pred_img, x_start\n\n    @torch.no_grad()\n    def p_sample_loop(self, shape, return_all_timesteps = False):\n        batch, device = shape[0], self.betas.device\n\n        img = torch.randn(shape, device = device)\n        imgs = [img]\n\n        x_start = None\n        \n        ###########################################\n        ## TODO: plot the sampling process ##\n        ###########################################\n        for t in tqdm(reversed(range(0, self.num_timesteps)), desc = 'sampling loop time step', total = self.num_timesteps):\n            img, x_start = self.p_sample(img, t)\n            imgs.append(img)\n        \n        ret = img if not return_all_timesteps else torch.stack(imgs, dim = 1)\n\n        ret = self.unnormalize(ret)\n        return ret\n\n    @torch.no_grad()\n    def sample(self, batch_size = 16, return_all_timesteps = False):\n        image_size, channels = self.image_size, self.channels\n        sample_fn = self.p_sample_loop\n        return sample_fn((batch_size, channels, image_size, image_size), return_all_timesteps = return_all_timesteps)\n\n\n    def q_sample(self, x_start, t, noise=None):\n        noise = default(noise, lambda: torch.randn_like(x_start))\n\n        return (\n            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +\n            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise\n        )\n\n    @property\n    def loss_fn(self):\n        return F.mse_loss\n\n\n    def p_losses(self, x_start, t, noise = None):\n        b, c, h, w = x_start.shape\n        noise = default(noise, lambda: torch.randn_like(x_start))\n\n        # noise sample\n\n        x = self.q_sample(x_start = x_start, t = t, noise = noise)\n\n        # predict and take gradient step\n\n        model_out = self.model(x, t)\n\n        loss = self.loss_fn(model_out, noise, reduction = 'none')\n        loss = reduce(loss, 'b ... -> b (...)', 'mean')\n\n        loss = loss * extract(self.loss_weight, t, loss.shape)\n        return loss.mean()\n\n    def forward(self, img, *args, **kwargs):\n        b, c, h, w, device, img_size, = *img.shape, img.device, self.image_size\n        assert h == img_size and w == img_size, f'height and width of image must be {img_size}'\n        t = torch.randint(0, self.num_timesteps, (b,), device=device).long()\n\n        img = self.normalize(img)\n        return self.p_losses(img, t, *args, **kwargs)\n","metadata":{"id":"X7TKWoZpInQs","execution":{"iopub.status.busy":"2024-06-28T11:52:31.412131Z","iopub.execute_input":"2024-06-28T11:52:31.412692Z","iopub.status.idle":"2024-06-28T11:52:31.456182Z","shell.execute_reply.started":"2024-06-28T11:52:31.412653Z","shell.execute_reply":"2024-06-28T11:52:31.455293Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Define Trainer: define the updating process","metadata":{"id":"yWJUjFIHInQt"}},{"cell_type":"code","source":"class Trainer(object):\n    def __init__(\n        self,\n        diffusion_model,\n        folder,\n        *,\n        train_batch_size = 16,\n        gradient_accumulate_every = 1,\n        train_lr = 1e-4,\n        train_num_steps = 100000,\n        ema_update_every = 10,\n        ema_decay = 0.995,\n        adam_betas = (0.9, 0.99),\n        save_and_sample_every = 1000,\n        num_samples = 25,\n        results_folder = './results',\n        split_batches = True,\n        inception_block_idx = 2048\n    ):\n        super().__init__()\n\n        # accelerator\n\n        self.accelerator = Accelerator(\n            split_batches = split_batches,\n            mixed_precision = 'no'\n        )\n        \n\n        # model\n\n        self.model = diffusion_model\n        self.channels = diffusion_model.channels\n\n        # sampling and training hyperparameters\n\n        assert has_int_squareroot(num_samples), 'number of samples must have an integer square root'\n        self.num_samples = num_samples\n        self.save_and_sample_every = save_and_sample_every\n\n        self.batch_size = train_batch_size\n        self.gradient_accumulate_every = gradient_accumulate_every\n\n        self.train_num_steps = train_num_steps\n        self.image_size = diffusion_model.image_size\n\n        # dataset and dataloader\n\n        self.ds = Dataset(folder, self.image_size)\n        dl = DataLoader(self.ds, batch_size = train_batch_size, shuffle = True, pin_memory = True, num_workers = cpu_count())\n\n        dl = self.accelerator.prepare(dl)\n        self.dl = cycle(dl)\n\n        # optimizer\n\n        self.opt = Adam(diffusion_model.parameters(), lr = train_lr, betas = adam_betas)\n\n        # for logging results in a folder periodically\n\n        if self.accelerator.is_main_process:\n            self.ema = EMA(diffusion_model, beta = ema_decay, update_every = ema_update_every)\n            self.ema.to(self.device)\n\n        self.results_folder = Path(results_folder)\n        self.results_folder.mkdir(exist_ok = True)\n\n        # step counter state\n\n        self.step = 0\n\n        # prepare model, dataloader, optimizer with accelerator\n\n        self.model, self.opt = self.accelerator.prepare(self.model, self.opt)\n\n    @property\n    def device(self):\n        return self.accelerator.device\n\n    def save(self, milestone):\n        if not self.accelerator.is_local_main_process:\n            return\n\n        data = {\n            'step': self.step,\n            'model': self.accelerator.get_state_dict(self.model),\n            'opt': self.opt.state_dict(),\n            'ema': self.ema.state_dict(),\n            'scaler': self.accelerator.scaler.state_dict() if exists(self.accelerator.scaler) else None,\n        }\n\n        torch.save(data, str(self.results_folder / f'model-{milestone}.pt'))\n\n    def load(self, ckpt):\n        accelerator = self.accelerator\n        device = accelerator.device\n\n        data = torch.load(ckpt, map_location=device)\n\n        model = self.accelerator.unwrap_model(self.model)\n        model.load_state_dict(data['model'])\n\n        self.step = data['step']\n        self.opt.load_state_dict(data['opt'])\n        if self.accelerator.is_main_process:\n            self.ema.load_state_dict(data[\"ema\"])\n\n\n        if exists(self.accelerator.scaler) and exists(data['scaler']):\n            self.accelerator.scaler.load_state_dict(data['scaler'])\n\n\n    def train(self):\n        accelerator = self.accelerator\n        device = accelerator.device\n\n        with tqdm(initial = self.step, total = self.train_num_steps, disable = not accelerator.is_main_process) as pbar:\n\n            while self.step < self.train_num_steps:\n\n                total_loss = 0.\n\n                for _ in range(self.gradient_accumulate_every):\n                    data = next(self.dl).to(device)\n\n                    with self.accelerator.autocast():\n                        loss = self.model(data)\n                        loss = loss / self.gradient_accumulate_every\n                        total_loss += loss.item()\n\n                    self.accelerator.backward(loss)\n\n                accelerator.clip_grad_norm_(self.model.parameters(), 1.0)\n                pbar.set_description(f'loss: {total_loss:.4f}')\n\n                accelerator.wait_for_everyone()\n\n                self.opt.step()\n                self.opt.zero_grad()\n\n                accelerator.wait_for_everyone()\n\n                self.step += 1\n                if accelerator.is_main_process:\n                    self.ema.update()\n\n                    if self.step != 0 and self.step % self.save_and_sample_every == 0:\n                        self.ema.ema_model.eval()\n\n                        with torch.no_grad():\n                            milestone = self.step // self.save_and_sample_every\n                            batches = num_to_groups(self.num_samples, self.batch_size)\n                            all_images_list = list(map(lambda n: self.ema.ema_model.sample(batch_size=n), batches))\n\n                        all_images = torch.cat(all_images_list, dim = 0)\n\n                        utils.save_image(all_images, str(self.results_folder / f'sample-{milestone}.png'), nrow = int(math.sqrt(self.num_samples)))\n                        \n                        self.save(milestone)\n\n                pbar.update(1)\n\n        accelerator.print('training complete')\n        \n    def inference(self, num=1000, n_iter=5, output_path='./submission'):\n        if not os.path.exists(output_path):\n            os.mkdir(output_path)\n        with torch.no_grad():\n            for i in range(n_iter):\n                batches = num_to_groups(num // n_iter, 200)\n                all_images = list(map(lambda n: self.ema.ema_model.sample(batch_size=n), batches))[0]\n                for j in range(all_images.size(0)):\n                    torchvision.utils.save_image(all_images[j], f'{output_path}/{i * 200 + j + 1}.jpg')              \n                ","metadata":{"id":"Ed12NNXPtDon","execution":{"iopub.status.busy":"2024-06-28T11:52:31.457764Z","iopub.execute_input":"2024-06-28T11:52:31.458141Z","iopub.status.idle":"2024-06-28T11:52:31.492574Z","shell.execute_reply.started":"2024-06-28T11:52:31.458105Z","shell.execute_reply":"2024-06-28T11:52:31.491679Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Training Hyper-parameters","metadata":{"id":"TZM7HR-UInQu"}},{"cell_type":"code","source":"path = '/kaggle/input/diffusion/faces/faces'\nIMG_SIZE = 64             # Size of images, do not change this if you do not know why you need to change\nbatch_size = 16\ntrain_num_steps = 100000        # total training steps\nlr = 1e-3\ngrad_steps = 1            # gradient accumulation steps, the equivalent batch size for updating equals to batch_size * grad_steps = 16 * 1\nema_decay = 0.995           # exponential moving average decay\n\nchannels = 16             # Numbers of channels of the first layer of CNN\ndim_mults = (1, 2, 4)        # The model size will be (channels, 2 * channels, 4 * channels, 4 * channels, 2 * channels, channels)\n\ntimesteps = 200            # Number of steps (adding noise)\nbeta_schedule = 'cos'\n\nmodel = Unet(\n    dim = channels,\n    dim_mults = dim_mults\n)\n\ndiffusion = GaussianDiffusion(\n    model,\n    image_size = IMG_SIZE,\n    timesteps = timesteps,\n    beta_schedule = beta_schedule\n)\n\ntrainer = Trainer(\n    diffusion,\n    path,\n    train_batch_size = batch_size,\n    train_lr = lr,\n    train_num_steps = train_num_steps,\n    gradient_accumulate_every = grad_steps,\n    ema_decay = ema_decay,\n    save_and_sample_every = 1000\n)\n\ntrainer.train()","metadata":{"id":"wOZPtVPvInQu","execution":{"iopub.status.busy":"2024-06-28T11:52:31.495450Z","iopub.execute_input":"2024-06-28T11:52:31.495722Z","iopub.status.idle":"2024-06-28T14:28:14.429253Z","shell.execute_reply.started":"2024-06-28T11:52:31.495697Z","shell.execute_reply":"2024-06-28T14:28:14.427966Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9376becf2ff240289718a889ca72e6a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4058478905e74559b84dfbb388f1deca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a99099ed1c0448a4b97e592efce0c164"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9216498f02a486b80b350b1dc36a332"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9369ee18b0f3447c80b36de60cedd97c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2750edf1daaf4454bfc05e7fa2079248"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95539387f82843768296de56aa18f937"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebc6d2d09d624c25adf0dbe92a0a4aa7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22a2659ca13b41d0a6b63f396c5cb7a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80004a3844d74558bfb8011b7c3ca970"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bffbb8b0bcb4b77975f4614ad58fb7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d55671623944b10b826b63feb820c51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f46e7483cc7049b28cbae8712f6ce98d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d76c07c2849d4e45b3ccd0339c0485fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9496460a2ae1482984c4eed9c26fc206"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19a968e46e094fb0973e610710d980b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e7cd66c6956468fbbfdba78dd99e019"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b07ce62aef744ecb8f51fc3bd8084a44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3deb950c76cd44f89f061d68a8ec428a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"573ca820b0a041f39415576fbc01fc08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc2be25eb8b24ea1b986a341f84976f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a666d0032483485298634786909907d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37457e8871be46aca4d8b7567b8f8a55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcc4147fbdfb4e2483f6027beb9f5703"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92ff68bc1084490a9291d704b02bcef4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f8319efe2a548cf8a54bad6430cb6fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"026dc57df4454c799d8efe885164f4e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbf4808d77a84ddd8a98b3d518d1c7ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77ad74f5e39d4b85b1ed080428145f8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1e7dd6e9b484e6bb512cdb1fb3331e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8693c167925c4cefb1a3e92e7b018e34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c627ed6468e46e5b0de8f94e25656ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6fc0039a238448b98b2962f65a764d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2d12d950de744aba0d43bba532c4a20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b55623320de44ee381be9225abc31de4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d96a311f387449b3846b08cc3f3e036d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b7bd15db21741fbbc88ceaee28c96ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eae8b457351b425fa29425a2052939cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a76c3202c9c472fb9e9727949755c07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d63b3e93da0e4a63b3d8a65170c7c5a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40dd5b9a8ae64d3f8aa81f4c55a14366"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e468fc6165f24d50ba7b86c0f7074583"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dd562bf760e4b65aa19ed6a7e67fb6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03088b8c3cf04689aba051abf36becff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f853789b61364ea88b33e430bde7512c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be3bb7ce5b874b2abd6c5b51e3dc6a05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e337815977cf4f9284fdb0f6dd17533b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"098023d6ff824d20a3365ddf509b8bce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bc231163b6f4c6588d0e20bd767f350"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"515b85d2b7f24159b5e24819ef7e764d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fd69e54b6d04209bae230e783aabbb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3237b317e15f499caf504d05a40573bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38b865504f884378b1b8575861d0a2ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26733e621bb540f0beaedbce1abd223e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4aa84f6ddb2543e690cd26bede636456"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19d57a5d2a98403ab38a9550d5422ab3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"110305af4d3b4991888a5827bca4c3f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2a206c9c15d4155bdf1e89ffd149301"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1550654f6124c9091ae2c87a394c1fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28155e656c604b57bc11f17e481fd03c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0771623e410c4ed89f1fe3f29e4ef2e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e0f1995064e4c26aa32c5d65bbfc1b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55f66d2e8dde48eb97922dff99cf48b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fc3f2654e5442048a4a3101ed42e161"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a59057f5834467493bcca2db2a7ab27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70bc419ffe2443e5b8a6e136eef43b28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf08859028b84e99b69a28c9957a675a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"166f58ba496149cab4dfae79086a3c93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c236b8155894014b2b7d087dd644734"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9858d1450eb481baa788e09adbcd59a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f7c4c08067d4bd2968d5fef340e99c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"453d20aad536474d9d5ff1f936ff0044"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d68cfe01fea8495ea64e1efa014b31f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"152800a54e4d48d39fe6f9bd4b7f10dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40f8502377914587b6c776cd93bb2177"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"131b8b7bae9f443da20716f7d25152d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5eff0cc5d6e409bbe04fdabc257da1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e75710ba728e49d58a359e7229694a2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8552fa408b7a4ef9b1e98ecffdd3a944"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfa980887f5b48fd843d4674587f837b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d2bca39901243c8b1c71bd607ef51ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24fff93a9b3d42cfb30f442c488c238f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be2e76f49bcc45d6bf9437b7a24bd9cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b91d4e15021a49d9bd573da4d221fe9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72abbbb988974ceca2b4179a7c558c20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"503aa4b5254743a18070296fda564516"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52c261ac53804e869e38ddea93dd2b1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17b7f87eac494ec59bdf2baf2221b93a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9521297eb234f0aa8af496d051edcd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9c36506f75b48a5a19fb89289dce519"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b94fffda74b5444ebdcc3e7c9538305a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27f06daf2bc2425dbab39dd743653375"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1db21d94e4f24646a4126193ccbc1708"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e64533b3c35a4d4c8653c0aabb613703"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d04219a3ac6543f6b883a442e5c90b64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c4c315851aa402198add46efaaf12a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"008166e486df4e8ba56fb735619a9067"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16569e9b97e441589585ee1036de3152"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04fb0f36ac0a4718ba14bf9c0a04e6a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a470812a6b749fc93e0f75afdd0a669"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dfeb6ad581f46f38ee428e68cee8340"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"870f49e036244d19b17a9519e4b5601b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46fac572bc4341e09469b653a13c89ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ac836e937e648a09d6026ce855932e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a04b6d792e6b4c10bee45bd93ec15aa3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6e5743a077d46e5a50724dd0ed3307e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"700ff1c09f9a4d46b1065359b993d9d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31c9d363a77e4febb4cab35a2b030eb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cabcc667becc480cb158702acb54438e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8cf936dc1634d739ac8b67efee082ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95e966b9e71e4e73b5e5f1becaadf56c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fafc0b14b23c415e86ef7c090333005f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35ce75bc284a41feb78ac3ddc3df9c18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb3529619f1846a1831cb177e9c64254"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2163bcae72542d7bde32d7d803d1498"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5d8e727fbb2426ba57439d1ca7daf72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"466c521abe824240b8297900190f24ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99546dbbfaa643619fb064c87c450bb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3292ce95f0eb490eb85e414bb7d2ab21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abb03829985244c2a15a97c3a94652f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bba24d2b83424e68926e97e79e154826"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2d2dd11d9d44e38a51d1343bbc4ac41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f6dd9d8041e47f8b160e8b94e399e9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14cb51eb2910472c9e0181cc1f1dd2f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4022c9fc737f482e95c8d2c139bc093d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6a66c6cde1a42e0abaaa16f7b6fd24e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e7b3f3e23ce41c9ab20bf474016c027"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f698b143c6f4f02be12b02c22a4385c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a515b2ba52d4d0a8277900e315c5829"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6de2c6a44de42b584ac1e779951affe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61c6c9e723434d5f9eefc95f687f191a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8cc14f975c84f6999208802ccc3a70c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"055987b74d8f4312ababf1331696c2df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a180879ecac2427d919141a91c6394d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce5aa861d4c24dab897fe1d8fee8e938"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de6993a779e74a5997c8d30703ba24f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8463ec33e847438d9a337492e7a91d00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4eb3587f6c054b4c8eef15497dab7927"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"734ba7ff3e0249a9afbc83791f68fbb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab0a5b621b984132ae4998fb92df540b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3c6f02a2839473abfe0861c5b6208da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"490624fc08c44427a7a6a23276e4edff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"198579d70375413d93656c84663fa210"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e8a4182da3a46b7b1754b51b740424a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ceb699c8d5804bf5bbe844fa55bb2ab2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cdd2f2cd9974590836d64e3e2745898"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7a4ebae4a7b48e69a29d92e2a8b2cb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b634a16a1f1449ea3f7cb6b81ff6b31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"457a326779e4471680cc201d16c1ee78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dc68552cef14d84993849e42f4370a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f08c1bd8a424af3a0cf917a9a967cec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a08c2bb3504d4dd6b6de680f4d174700"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c037d4c21b464ba182e8101e0c0f43f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8af8b90dc0764113986ab52b101df17c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27f88f9aa9fb4e249d1f5f62d30db3f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9776188fe8244ea49b45af9c0e5d9be8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1819f5a3e8fe40af92590a7222d13bae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f68b624415064d5abc172b1a188df72f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af43acff112c478884b99c63d9593887"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b07a900006e4343ae2ca4395347ad0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"283a6dbd06234bdabfc03dcdec1a2a67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4c01bdabd4d426cabdddfab5c13c53a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6470410cbd04743b511362f20c9a5cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc3623e9587b428a8709318e506ecafd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2200fd2fdcf44a9490ee93cf2a3ad870"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81662b05bba24a87b1309221cfd41f1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84977205b11648fdb41d140eee054b97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc58525a83424d30956c869f399c636f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"924ca91cff8c4c20ac42cb9bd0b9d570"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"560f3f2e1e8143639a8dee04333adad4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d87af124519d4ec7bb8bc40ca9a6e360"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3a3048782f845608c4488ea9156cdaa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df2421462bb54f5f8538b4791ab9c90f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0d449f094144558be7393aa54ef41e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dee8ba688934ee49cfbda79269a9bc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fc8e92be6b1470c8d0443329db71048"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b01cd829b662438a9515efaeddcb43d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9eb00407ae0048e18999f390e3877568"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aad6f221b4f2493e98fefa890aaec2a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5643612ff4cf46d28634478fbb248d73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f28d4afac9864adc9e8b32ec128dac55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79a4680bc3f6426c9ae2f717a195f17d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e59e5287a1443288f89ee5e4fc3a4b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b8832acb1c046d49ee8730e4d7126be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccd0285b355d41ca91da59b7040dcb92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0889c7edfa484adc8bac251f1d4d527c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62e24fa931a243e6a7fdc7258551d09c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17dd617dacf6446db285854172f9af65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a456de990cef4d9ea66893d025041c56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cf11411bc3f4ddf9e5ed28588f507eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7aa0cfd09d184dfdbea794ba1635923a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0c8a85c526d4e01aa4f4b45eb20d8a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d0ceb62857940f79625a9cd91aa45b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1167f40d8339475192e6362e3d05be67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f5967d6aeda499b8e14cbf1fa91b9ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"008ed026381b48c3bf0f41f068300039"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a14dd51d3c8c4a99beae5fdaeedc66f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d99ca1518914615afa9dbf828ebec3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88da2c23f79c41daac0ac0b6f99cd3fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"231b1780dec54178b0c38784db1f270b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc2e63375d7a46babe4560ed2b789cba"}},"metadata":{}},{"name":"stdout","text":"training complete\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Inference","metadata":{"id":"SV7OL7PvInQu"}},{"cell_type":"code","source":"ckpt = '/kaggle/working/results/model-55.pt'\ntrainer.load(ckpt)\ntrainer.inference()\n","metadata":{"id":"MHoY_6CrInQv","outputId":"010af6c5-a426-42cd-b560-721fff3baa84","execution":{"iopub.status.busy":"2024-06-28T14:28:14.432000Z","iopub.execute_input":"2024-06-28T14:28:14.432338Z","iopub.status.idle":"2024-06-28T14:30:55.386492Z","shell.execute_reply.started":"2024-06-28T14:28:14.432303Z","shell.execute_reply":"2024-06-28T14:30:55.385621Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fea23e5234564118886b98fc9e2cf1ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75e18beb2af3409ead8329408e1cb12a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"814da224b4d1460d986f3cb7fc6ef5a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46fd73e4a33d499a9c548d1d0be34491"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb910c7aa96c4953999474cd32724cea"}},"metadata":{}}]},{"cell_type":"code","source":"%cd ./submission\n!tar -zcf ../submission.tgz *.jpg\n%cd ..","metadata":{"id":"GkWpuU-2KzIL","outputId":"2215341d-4f7f-48c3-85ac-403e9ad2cb27","execution":{"iopub.status.busy":"2024-06-28T14:30:55.387971Z","iopub.execute_input":"2024-06-28T14:30:55.388440Z","iopub.status.idle":"2024-06-28T14:30:56.466007Z","shell.execute_reply.started":"2024-06-28T14:30:55.388399Z","shell.execute_reply":"2024-06-28T14:30:56.464647Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"/kaggle/working/submission\n/kaggle/working\n","output_type":"stream"}]}]}